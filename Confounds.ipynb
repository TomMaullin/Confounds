{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5ca79ab",
   "metadata": {},
   "source": [
    "# UK Biobank Confounds Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a06740",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190478fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time \n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from lib.script_01_00 import generate_initial_variables\n",
    "from lib.script_01_01 import generate_raw_confounds\n",
    "from lib.script_01_02 import generate_nonlin_confounds\n",
    "from lib.script_01_03_to_4 import get_p_vals_and_ve\n",
    "from lib.script_01_06_to_8 import threshold_ve\n",
    "\n",
    "from src.nets.nets_load_match import nets_load_match\n",
    "from src.nets.nets_inverse_normal import nets_inverse_normal \n",
    "from src.nets.nets_normalise import nets_normalise \n",
    "from src.nets.nets_demean import nets_demean\n",
    "from src.nets.nets_deconfound import nets_deconfound\n",
    "\n",
    "from src.memmap.MemoryMappedDF import MemoryMappedDF\n",
    "from src.memmap.read_memmap_df import read_memmap_df\n",
    "from src.memmap.addBlockToMmap import addBlockToMmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba155a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/well/win/projects/ukbiobank/fbp/confounds/data/72k_data/'\n",
    "\n",
    "# Output directory (will eventually be equal to data_dir)\n",
    "out_dir = '/well/nichols/users/inf852/confounds/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089c571a",
   "metadata": {},
   "source": [
    "## Script 01_00: gen_init_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5094e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you set skip to True, we will skip script 01_00 and load in a presaved output\n",
    "skip = True\n",
    "\n",
    "# Run notebook 00\n",
    "if not skip:\n",
    "\n",
    "    # Time the notebook\n",
    "    t1 = time.time()\n",
    "    IDPs, nonIDPs, misc = generate_initial_variables(data_dir, out_dir)\n",
    "    t2 = time.time()\n",
    "\n",
    "    # Print the time\n",
    "    print(t2-t1)\n",
    "    \n",
    "    # Files we can reconstruct memory mapped dataframes from\n",
    "    IDPs_fname = os.path.join(os.getcwd(),'saved_memmaps','IDPs.npz')\n",
    "    nonIDPs_fname = os.path.join(os.getcwd(),'saved_memmaps','nonIDPs.npz')\n",
    "    misc_fname = os.path.join(os.getcwd(),'saved_memmaps','misc.npz')\n",
    "\n",
    "    # Save the results\n",
    "    IDPs.save(IDPs_fname)\n",
    "    nonIDPs.save(nonIDPs_fname)\n",
    "    misc.save(misc_fname)\n",
    "    \n",
    "    \n",
    "else: \n",
    "    \n",
    "    # Read in precomputed memmaps\n",
    "    IDPs = read_memmap_df(os.path.join(os.getcwd(),'saved_memmaps','IDPs.npz'))\n",
    "    nonIDPs = read_memmap_df(os.path.join(os.getcwd(),'saved_memmaps','nonIDPs.npz'))\n",
    "    misc = read_memmap_df(os.path.join(os.getcwd(),'saved_memmaps','misc.npz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747524c8",
   "metadata": {},
   "source": [
    "*The previous run of notebook zero took 246.62735080718994 seconds ≈ 4.1 minutes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38458efa",
   "metadata": {},
   "source": [
    "## Script 01_01: gen_raw_conf_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad4e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the subject IDs\n",
    "sub_ids = IDPs.index\n",
    "\n",
    "# If you set skip to True, we will skip script 01_01 and load in a presaved output\n",
    "skip = True\n",
    "\n",
    "# Run script 01\n",
    "if not skip:\n",
    "\n",
    "    # Generate raw confounds\n",
    "    t1 = time.time()\n",
    "    confounds = generate_raw_confounds(data_dir, sub_ids)\n",
    "    t2 = time.time()\n",
    "\n",
    "    # Print the time\n",
    "    print(t2-t1)\n",
    "\n",
    "\n",
    "    # Files we can reconstruct memory mapped dataframes from\n",
    "    confounds_fname = os.path.join(os.getcwd(),'saved_memmaps','confounds.npz')\n",
    "\n",
    "    # Save the results\n",
    "    confounds.save(confounds_fname)\n",
    "    \n",
    "    \n",
    "else:\n",
    "    \n",
    "    # Read in precomputed confounds\n",
    "    confounds = read_memmap_df(os.path.join(os.getcwd(),'saved_memmaps','confounds.npz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8c69b9",
   "metadata": {},
   "source": [
    "*Previous run took 12.58459210395813 seconds.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c87bdf",
   "metadata": {},
   "source": [
    "## Script 01_02: gen_nonlin_conf_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5368bff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you set skip to True, we will skip script 01_02 and load in a presaved output\n",
    "skip = True\n",
    "\n",
    "# Run script 02\n",
    "if not skip:\n",
    "\n",
    "    # Set cluster configuration\n",
    "    local_cluster = {'cluster_type':'local','num_nodes':12}\n",
    "\n",
    "    # Generate non linear confounds and deconfound IDPs\n",
    "    t1 = time.time()\n",
    "    nonlinear_confounds, IDPs_deconf = generate_nonlin_confounds(data_dir, confounds, IDPs, local_cluster)\n",
    "    t2 = time.time()\n",
    "\n",
    "    # Time the notebook\n",
    "    print(t2-t1)\n",
    "\n",
    "    # Save the results as files we can reconstruct memory mapped dataframes from\n",
    "    nonlinear_confounds_fname = os.path.join(os.getcwd(),'saved_memmaps','nonlinear_confounds.npz')\n",
    "    nonlinear_confounds.save(nonlinear_confounds_fname)\n",
    "    \n",
    "    # Save the results as files we can reconstruct memory mapped dataframes from\n",
    "    IDPs_deconf_fname = os.path.join(os.getcwd(),'saved_memmaps','IDPs_deconf.npz')\n",
    "    IDPs_deconf.save(IDPs_deconf_fname)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # Read in precomputed confounds\n",
    "    nonlinear_confounds_fname = os.path.join(os.getcwd(),'saved_memmaps','nonlinear_confounds.npz')\n",
    "    nonlinear_confounds = read_memmap_df(nonlinear_confounds_fname)\n",
    "\n",
    "    # Read in precomputed IDPs\n",
    "    IDPs_deconf_fname = os.path.join(os.getcwd(),'saved_memmaps','IDPs_deconf.npz')\n",
    "    IDPs_deconf = read_memmap_df(IDPs_deconf_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f2cf93",
   "metadata": {},
   "source": [
    "*Last local cluster run (12 nodes) took 687.3723814487457 seconds ≈ 11.45 minutes.*\n",
    "\n",
    "*Comparison on the same machine; MatLab local cluster run (12 nodes) took 2305.303473 seconds ≈ 38.4 minutes.* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e6eda6",
   "metadata": {},
   "source": [
    "## Script 01_03_to_4: gen_jobs/gen_nonlin_conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d35859-12af-47bc-9a1e-3a1c761d1393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you set skip to True, we will skip script 01_03 and load in a presaved output\n",
    "skip = True\n",
    "\n",
    "# Run scripts 03-04\n",
    "if not skip:\n",
    "\n",
    "    # Set cluster configuration\n",
    "    dask_cluster = {'cluster_type':'slurm','num_nodes':100}\n",
    "\n",
    "    # Generate non linear confounds and deconfound IDPs\n",
    "    t1 = time.time()\n",
    "    p1, p2, p3, ve1, ve2, ve3 = get_p_vals_and_ve(data_dir, nonlinear_confounds, IDPs_deconf, cluster_cfg=dask_cluster)\n",
    "    t2 = time.time()\n",
    "\n",
    "    # Time the notebook\n",
    "    print(t2-t1)\n",
    "\n",
    "    # Create filenames for p-value memory mapped dataframes to save\n",
    "    p1_fname = os.path.join(os.getcwd(),'saved_memmaps','p1.npz')\n",
    "    p2_fname = os.path.join(os.getcwd(),'saved_memmaps','p2.npz')\n",
    "    p3_fname = os.path.join(os.getcwd(),'saved_memmaps','p3.npz')\n",
    "\n",
    "    # Save memory mapped dataframes\n",
    "    p1.save(p1_fname)\n",
    "    p2.save(p2_fname)\n",
    "    p3.save(p3_fname)\n",
    "    \n",
    "    # Create filenames for variance explained memory mapped dataframes to save\n",
    "    ve1_fname = os.path.join(os.getcwd(),'saved_memmaps','ve1.npz')\n",
    "    ve2_fname = os.path.join(os.getcwd(),'saved_memmaps','ve2.npz')\n",
    "    ve3_fname = os.path.join(os.getcwd(),'saved_memmaps','ve3.npz')\n",
    "\n",
    "    # Save memory mapped dataframes\n",
    "    ve1.save(ve1_fname)\n",
    "    ve2.save(ve2_fname)\n",
    "    ve3.save(ve3_fname)\n",
    "    \n",
    "else:\n",
    "\n",
    "    # Precomputed filenames\n",
    "    p1_fname = os.path.join(os.getcwd(),'saved_memmaps','p1.npz')\n",
    "    p2_fname = os.path.join(os.getcwd(),'saved_memmaps','p2.npz')\n",
    "    p3_fname = os.path.join(os.getcwd(),'saved_memmaps','p3.npz')\n",
    "    ve1_fname = os.path.join(os.getcwd(),'saved_memmaps','ve1.npz')\n",
    "    ve2_fname = os.path.join(os.getcwd(),'saved_memmaps','ve2.npz')\n",
    "    ve3_fname = os.path.join(os.getcwd(),'saved_memmaps','ve3.npz')\n",
    "    \n",
    "    # Read in precomputed p and ve\n",
    "    p1 = read_memmap_df(p1_fname)\n",
    "    p2 = read_memmap_df(p2_fname)\n",
    "    p3 = read_memmap_df(p3_fname)\n",
    "    ve1 = read_memmap_df(ve1_fname)\n",
    "    ve2 = read_memmap_df(ve2_fname)\n",
    "    ve3 = read_memmap_df(ve3_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053c25c0-4086-424f-89e8-bfa194f63863",
   "metadata": {},
   "source": [
    "*Last SGE cluster run (100 nodes) took 2147.7868587970734 seconds ≈ 36 minutes.*\n",
    "\n",
    "*The Matlab version of 01_05 took approximately 15-20 minutes to run most of the analyses but several jobs did not complete. The code in matlab script_01_06 was run to regenerate the remaining p-values. This took approximately 2 days (for the cluster jobs to time out), plus 2 hours (for the regeneration of the remaining values).*\n",
    "\n",
    "A large factor in the above computation times is the method used to submit jobs. Iteration for iteration, the matlab took between 30-60 seconds and the Python took between 20-40 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3f032a-8b79-4998-9f34-a62ba23b6b7b",
   "metadata": {},
   "source": [
    "## Script 01_05: gen_nonlin_conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d957ea-bf6f-4286-be38-07d34f5aba18",
   "metadata": {},
   "source": [
    "This code is called to by `script_01_03-04.py` and does not need to be run at this level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fbfb1c-1ac9-4ef3-9d4c-4af0d6229ccd",
   "metadata": {},
   "source": [
    "## Script 01_06_to_08: gen_nonlin_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac544b2-b326-4e58-965b-aa021df1a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you set skip to True, we will skip script 01_03 and load in a presaved output\n",
    "skip = True\n",
    "\n",
    "# Run script 06-08\n",
    "if not skip:\n",
    "\n",
    "    # Work out thresholded variance explaineds\n",
    "    t1 = time.time()\n",
    "    nonlinear_confounds_reduced = threshold_ve(ve1, nonlinear_confounds, out_dir)\n",
    "    t2 = time.time()\n",
    "\n",
    "    # Time the notebook\n",
    "    print(t2-t1)\n",
    "    \n",
    "    # Create filename for reduced nonlinear confounds \n",
    "    nonlinear_confounds_reduced_fname = os.path.join(os.getcwd(),'saved_memmaps','nonlinear_confounds_reduced.npz')\n",
    "\n",
    "    # Save memory mapped dataframe\n",
    "    nonlinear_confounds_reduced.save(nonlinear_confounds_reduced_fname)\n",
    "\n",
    "# Otherwise load in\n",
    "else:\n",
    "    \n",
    "    # Precomputed filenames\n",
    "    nonlinear_confounds_reduced_fname = os.path.join(os.getcwd(),'saved_memmaps','nonlinear_confounds_reduced.npz')\n",
    "    \n",
    "    # Read in precomputed\n",
    "    nonlinear_confounds_reduced = read_memmap_df(nonlinear_confounds_reduced_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada8fac-c1c9-42b9-970d-10f1858dcd94",
   "metadata": {},
   "source": [
    "*Previous run took 9.174669981002808 seconds*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787bfd1f",
   "metadata": {},
   "source": [
    "## Garbage Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1361e562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this won't execute in Jupyter until the code is restarted.\n",
    "#del IDPs, nonIDPs, misc, categorical_IDPs, continuous_IDPs, other_IDPs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
