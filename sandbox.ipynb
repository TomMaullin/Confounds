{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eb7b85f",
   "metadata": {},
   "source": [
    "## Sandbox notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ac6a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time \n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.precision\", 20)\n",
    "\n",
    "from lib.script_01_00 import generate_initial_variables\n",
    "from lib.script_01_01 import generate_raw_confounds\n",
    "from lib.script_01_02 import generate_nonlin_confounds\n",
    "\n",
    "from src.nets.nets_load_match import nets_load_match\n",
    "from src.nets.nets_inverse_normal import nets_inverse_normal \n",
    "from src.nets.nets_normalise import nets_normalise \n",
    "from src.nets.nets_demean import nets_demean\n",
    "from src.nets.nets_deconfound import nets_deconfound\n",
    "\n",
    "from src.duplicate.duplicate_categorical import duplicate_categorical\n",
    "from src.duplicate.duplicate_demedian_norm_by_site import duplicate_demedian_norm_by_site\n",
    "\n",
    "from src.preproc.datenum import datenum\n",
    "from src.preproc.days_in_year import days_in_year\n",
    "\n",
    "from src.memmap.MemoryMappedDF import MemoryMappedDF\n",
    "from src.memmap.read_memmap_df import read_memmap_df\n",
    "from src.memmap.addBlockToMmap import addBlockToMmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82731372-cb80-4dca-aaec-ce4671396009",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/well/win/projects/ukbiobank/fbp/confounds/data/72k_data/'\n",
    "\n",
    "# Output directory (will eventually be equal to data_dir)\n",
    "out_dir = '/well/nichols/users/inf852/confounds/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e28b18-6668-4814-b992-8f08cd182a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read in precomputed memmaps\n",
    "IDPs = read_memmap_df(os.path.join(os.getcwd(),'saved_memmaps','IDPs.npz'))\n",
    "nonIDPs = read_memmap_df(os.path.join(os.getcwd(),'saved_memmaps','nonIDPs.npz'))\n",
    "misc = read_memmap_df(os.path.join(os.getcwd(),'saved_memmaps','misc.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8034efba-235f-4d87-a065-5ccb024814a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonIDPs[0:10,'AGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a564a8-e4f8-41da-acbe-58fc489ac0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the subject IDs\n",
    "sub_ids = IDPs.index\n",
    "\n",
    "# Data types for IDs\n",
    "dtypes = {0: 'int32', 1: 'Int16'}\n",
    "\n",
    "# Read in the IDs for site\n",
    "site_ids = nets_load_match(os.path.join(data_dir, 'ID_SITE.txt'), sub_ids)\n",
    "# Get the unique site ids\n",
    "unique_site_ids = np.unique(site_ids)\n",
    "\n",
    "# Initialize indSite as a list to hold the indices\n",
    "inds_per_site = []\n",
    "\n",
    "# Loop over each value in site ids\n",
    "for site_id in unique_site_ids:\n",
    "\n",
    "    # Find the indices where all elements in a row of siteDATA match the current valueSite\n",
    "    # Note: This assumes siteDATA and siteValues have compatible shapes or values for comparison\n",
    "    indices = np.where((site_ids == site_id).all(axis=1))[0]\n",
    "\n",
    "    # Append the found indices to the indSite list\n",
    "    inds_per_site.append(indices)\n",
    "\n",
    "# Delete the indices\n",
    "del indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2074a222-6792-4f79-b476-979f4016a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Construct confounds for between sites\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "# Get the number of rows in ALL_IDs\n",
    "n = len(sub_ids)\n",
    "\n",
    "# Initialize names_site list and conf_site matrix\n",
    "names_site = []\n",
    "conf_site = np.zeros((n, len(inds_per_site)-1))\n",
    "\n",
    "# Subjects from Site 1 will have -1 in all site confounds\n",
    "conf_site[inds_per_site[0], :] = -1\n",
    "\n",
    "# Subjects for the other sites will have -1 in their corresponding column\n",
    "# Value by default is 0\n",
    "for i in range(1, len(inds_per_site)):\n",
    "    conf_site[inds_per_site[i], i-1] = 1\n",
    "    names_site.append(f'Site_1_vs_{i+1}')\n",
    "\n",
    "# # Normalize conf_site using the nets_normalise function\n",
    "conf_site = nets_normalise(conf_site)\n",
    "conf_site[np.isnan(conf_site)] = 0\n",
    "\n",
    "# Make into dataframe\n",
    "conf_site = pd.DataFrame(conf_site)\n",
    "conf_site.columns = names_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0d2a22-5d31-4013-b0fb-adf9de2b3011",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Construct dummy confounds for categorical variables\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "# Construct dummy variables for the following\n",
    "conf_sex          = duplicate_categorical('SEX',         sub_ids, inds_per_site, data_dir)\n",
    "conf_batch        = duplicate_categorical('BATCH',       sub_ids, inds_per_site, data_dir)\n",
    "conf_cmrr         = duplicate_categorical('CMRR',        sub_ids, inds_per_site, data_dir)\n",
    "conf_protocol     = duplicate_categorical('PROTOCOL',    sub_ids, inds_per_site, data_dir)\n",
    "conf_service_pack = duplicate_categorical('SERVICEPACK', sub_ids, inds_per_site, data_dir)\n",
    "conf_scan_events  = duplicate_categorical('SCANEVENTS',  sub_ids, inds_per_site, data_dir)\n",
    "conf_flipped_swi  = duplicate_categorical('FLIPPEDSWI',  sub_ids, inds_per_site, data_dir)\n",
    "conf_fst2         = duplicate_categorical('FST2',        sub_ids, inds_per_site, data_dir)\n",
    "conf_new_eddy     = duplicate_categorical('NEWEDDY',     sub_ids, inds_per_site, data_dir)\n",
    "conf_scaling      = duplicate_categorical('SCALING',     sub_ids, inds_per_site, data_dir)\n",
    "conf_time_points  = duplicate_categorical('TIMEPOINTS',  sub_ids, inds_per_site, data_dir)\n",
    "\n",
    "# Concatenate all the DataFrames/Series horizontally\n",
    "categorical_IDPs = pd.concat([\n",
    "    conf_sex.reset_index(drop=True), \n",
    "    conf_batch.reset_index(drop=True),\n",
    "    conf_cmrr.reset_index(drop=True),\n",
    "    conf_protocol.reset_index(drop=True),\n",
    "    conf_service_pack.reset_index(drop=True),\n",
    "    conf_scan_events.reset_index(drop=True),\n",
    "    conf_flipped_swi.reset_index(drop=True),\n",
    "    conf_fst2.reset_index(drop=True),\n",
    "    conf_new_eddy.reset_index(drop=True),\n",
    "    conf_scaling.reset_index(drop=True),\n",
    "    conf_time_points.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "# Set row indices on dataframe\n",
    "categorical_IDPs.index = sub_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a321f49e-1dc2-45f7-84f8-2f0380b01d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Construct dummy confounds for continuous variables\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "# Construct dummy variables for the following\n",
    "conf_head_motion         = duplicate_demedian_norm_by_site('HEADMOTION',       sub_ids, inds_per_site, data_dir)\n",
    "conf_head_motion_st      = duplicate_demedian_norm_by_site('HEADMOTIONST',     sub_ids, inds_per_site, data_dir)\n",
    "conf_head_size           = duplicate_demedian_norm_by_site('HEADSIZE',         sub_ids, inds_per_site, data_dir)\n",
    "conf_table_pos           = duplicate_demedian_norm_by_site('TABLEPOS',         sub_ids, inds_per_site, data_dir)\n",
    "conf_dvars               = duplicate_demedian_norm_by_site('DVARS',            sub_ids, inds_per_site, data_dir)\n",
    "conf_eddy_qc             = duplicate_demedian_norm_by_site('EDDYQC',           sub_ids, inds_per_site, data_dir)\n",
    "conf_struct_head_motion  = duplicate_demedian_norm_by_site('STRUCTHEADMOTION', sub_ids, inds_per_site, data_dir)\n",
    "conf_age                 = duplicate_demedian_norm_by_site('AGE',              sub_ids, inds_per_site, data_dir)\n",
    "conf_te                  = duplicate_demedian_norm_by_site('TE',               sub_ids, inds_per_site, data_dir) \n",
    "\n",
    "# Concatenate all the DataFrames/Series horizontally\n",
    "continuous_IDPs = pd.concat([\n",
    "    conf_age.reset_index(drop=True),\n",
    "    conf_head_size.reset_index(drop=True),\n",
    "    conf_te.reset_index(drop=True),\n",
    "    conf_struct_head_motion.reset_index(drop=True),\n",
    "    conf_dvars.reset_index(drop=True),\n",
    "    conf_head_motion.reset_index(drop=True),\n",
    "    conf_head_motion_st.reset_index(drop=True), \n",
    "    conf_table_pos.reset_index(drop=True),\n",
    "    conf_eddy_qc.reset_index(drop=True),\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0bb9a3-c8c4-45ed-a7e9-67fbf6025f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Construct dummy confounds for age-sex interaction\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "# Initialize conf_age_sex with zeros of the same shape as conf_age\n",
    "conf_age_sex = pd.DataFrame(np.zeros_like(conf_age))\n",
    "\n",
    "# Loop over columns in conf_age\n",
    "for i in range(conf_age.shape[1]):\n",
    "\n",
    "    # Find indices where confAge is not zero\n",
    "    ind_non_zero = np.where(conf_age.iloc[:, i] != 0)[0]\n",
    "\n",
    "    # Apply nets_normalise to the product of confAge and confSex for non-zero age indices\n",
    "    conf_age_sex.iloc[ind_non_zero, i] = nets_normalise(conf_age.iloc[ind_non_zero, i] * conf_sex.iloc[ind_non_zero, i])\n",
    "\n",
    "    # Replace NaN values with 0, if any\n",
    "    conf_age_sex[np.isnan(conf_age_sex)] = 0\n",
    "\n",
    "# Generate names for AgeSex per site\n",
    "names_age_sex = [f'AgeSex_Site_{j}' for j in range(1, len(inds_per_site) + 1)]\n",
    "\n",
    "# Set column names for conf_age_sex\n",
    "conf_age_sex.columns = names_age_sex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8544812c-a9e9-426b-be07-e8074dfd4ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create confounds dataframe\n",
    "confounds = pd.concat([\n",
    "    conf_site.reset_index(drop=True),\n",
    "    categorical_IDPs.reset_index(drop=True),\n",
    "    continuous_IDPs.reset_index(drop=True),\n",
    "    conf_age_sex.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "# Save the index\n",
    "confounds.index = sub_ids\n",
    "\n",
    "# Get confounds memory mapped dataframe\n",
    "confounds = MemoryMappedDF(confounds)\n",
    "\n",
    "# Quick access of site variables\n",
    "confounds.set_group('SITE', conf_site.columns.tolist())\n",
    "\n",
    "# Add groups of categorical variable names for easy access\n",
    "confounds.set_group('SEX', conf_sex.columns.tolist())\n",
    "confounds.set_group('BATCH', conf_batch.columns.tolist())\n",
    "confounds.set_group('CMRR', conf_cmrr.columns.tolist())\n",
    "confounds.set_group('PROTOCOL', conf_protocol.columns.tolist())\n",
    "confounds.set_group('SERVICE_PACK', conf_service_pack.columns.tolist())\n",
    "confounds.set_group('SCAN_EVENTS', conf_scan_events.columns.tolist())\n",
    "confounds.set_group('FLIPPED_SWI', conf_flipped_swi.columns.tolist())\n",
    "confounds.set_group('FS_T2', conf_fst2.columns.tolist())\n",
    "confounds.set_group('NEW_EDDY', conf_new_eddy.columns.tolist())\n",
    "confounds.set_group('SCALING', conf_scaling.columns.tolist())\n",
    "confounds.set_group('TIMEPOINTS', conf_time_points.columns.tolist())\n",
    "\n",
    "# Add groups of continuous variable names for easy access\n",
    "confounds.set_group('AGE', conf_age.columns.tolist())\n",
    "confounds.set_group('HEAD_SIZE', conf_head_size.columns.tolist())\n",
    "confounds.set_group('TE', conf_te.columns.tolist())\n",
    "confounds.set_group('STRUCT_MOTION', conf_struct_head_motion.columns.tolist())\n",
    "confounds.set_group('DVARS', conf_dvars.columns.tolist())\n",
    "confounds.set_group('HEAD_MOTION', conf_head_motion.columns.tolist())\n",
    "confounds.set_group('HEAD_MOTION_ST', conf_head_motion_st.columns.tolist())\n",
    "confounds.set_group('TABLE_POS', conf_table_pos.columns.tolist())\n",
    "confounds.set_group('EDDY_QC', conf_eddy_qc.columns.tolist())\n",
    "\n",
    "# Add groups of age_sex variables for easy access\n",
    "confounds.set_group('AGE_SEX', conf_age_sex.columns.tolist())\n",
    "\n",
    "# Add group of subject level confounds\n",
    "confounds.set_group('SUBJECT', conf_age.columns.tolist() + \\\n",
    "                               conf_sex.columns.tolist() + \\\n",
    "                               conf_age_sex.columns.tolist() + \\\n",
    "                               conf_head_size.columns.tolist())\n",
    "\n",
    "# Add group of acquisition related confounds\n",
    "confounds.set_group('ACQ', conf_site.columns.tolist() + \\\n",
    "                           conf_batch.columns.tolist() + \\\n",
    "                           conf_cmrr.columns.tolist() + \\\n",
    "                           conf_protocol.columns.tolist() + \\\n",
    "                           conf_service_pack.columns.tolist() + \\\n",
    "                           conf_scan_events.columns.tolist() + \\\n",
    "                           conf_flipped_swi.columns.tolist() + \\\n",
    "                           conf_fst2.columns.tolist() + \\\n",
    "                           conf_new_eddy.columns.tolist() + \\\n",
    "                           conf_scaling.columns.tolist() + \\\n",
    "                           conf_te.columns.tolist() + \\\n",
    "                           conf_time_points.columns.tolist())\n",
    "\n",
    "# Add group of motion related confounds\n",
    "confounds.set_group('MOTION', conf_struct_head_motion.columns.tolist() + \\\n",
    "                              conf_dvars.columns.tolist() + \\\n",
    "                              conf_head_motion.columns.tolist() + \\\n",
    "                              conf_head_motion_st.columns.tolist())\n",
    "                    \n",
    "# Add group of table position related confounds\n",
    "confounds.set_group('TABLE', conf_table_pos.columns.tolist() + \\\n",
    "                             conf_eddy_qc.columns.tolist())\n",
    "\n",
    "\n",
    "# Delete previous dataframes\n",
    "del conf_site, categorical_IDPs, continuous_IDPs, conf_age_sex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf6f613-aaa1-4296-ae34-5b65bf579b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "confounds.groups['age_sex']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc9174e-50b2-4d60-a512-e06a49fc14fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704746b4-de19-45fc-bce5-6957d5e4b8ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44db1bb-84be-4a23-9806-f792c2449b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
