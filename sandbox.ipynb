{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eb7b85f",
   "metadata": {},
   "source": [
    "## Sandbox notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ac6a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time \n",
    "import shutil \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.precision\", 20)\n",
    "\n",
    "from lib.script_01_00 import generate_initial_variables\n",
    "from lib.script_01_01 import generate_raw_confounds\n",
    "from lib.script_01_02 import generate_nonlin_confounds\n",
    "\n",
    "from src.nets.nets_load_match import nets_load_match\n",
    "from src.nets.nets_inverse_normal import nets_inverse_normal \n",
    "from src.nets.nets_normalise import nets_normalise \n",
    "from src.nets.nets_demean import nets_demean\n",
    "from src.nets.nets_deconfound import nets_deconfound\n",
    "\n",
    "from src.duplicate.duplicate_categorical import duplicate_categorical\n",
    "from src.duplicate.duplicate_demedian_norm_by_site import duplicate_demedian_norm_by_site\n",
    "\n",
    "from src.preproc.datenum import datenum\n",
    "from src.preproc.days_in_year import days_in_year\n",
    "\n",
    "from src.memmap.MemoryMappedDF import MemoryMappedDF\n",
    "from src.memmap.read_memmap_df import read_memmap_df\n",
    "from src.memmap.addBlockToMmap import addBlockToMmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82731372-cb80-4dca-aaec-ce4671396009",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/well/win/projects/ukbiobank/fbp/confounds/data/72k_data/'\n",
    "\n",
    "# Output directory (will eventually be equal to data_dir)\n",
    "out_dir = '/well/nichols/users/inf852/confounds/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e28b18-6668-4814-b992-8f08cd182a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read in precomputed memmaps\n",
    "IDPs = read_memmap_df(os.path.join(os.getcwd(),'saved_memmaps','IDPs.npz'))\n",
    "nonIDPs = read_memmap_df(os.path.join(os.getcwd(),'saved_memmaps','nonIDPs.npz'))\n",
    "misc = read_memmap_df(os.path.join(os.getcwd(),'saved_memmaps','misc.npz'))\n",
    "confounds = read_memmap_df(os.path.join(os.getcwd(),'saved_memmaps','confounds.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f330dc8-2936-4d62-aa1c-aa018154544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.nets.nets_svd import nets_svd\n",
    "from src.nets.nets_demean import nets_demean\n",
    "from src.memmap.MemoryMappedDF import MemoryMappedDF\n",
    "from src.nantools.all_non_nan_inds import all_non_nan_inds\n",
    "from src.nantools.create_nan_patterns import create_nan_patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b84ab-981b-498b-9822-7708872bcee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.nets.nets_deconfound_once import inside_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262a18ab-3d36-4d16-b07b-16da57781de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.nets.nets_load_match import nets_load_match\n",
    "from src.preproc.filter_columns_by_site import filter_columns_by_site\n",
    "\n",
    "# Get the subject ids\n",
    "sub_ids = nonlinear_confounds_reduced.index\n",
    "\n",
    "# Read in the IDs for site\n",
    "site_ids = nets_load_match(os.path.join(data_dir, 'ID_SITE.txt'), sub_ids)\n",
    "\n",
    "# Get the unique site ids\n",
    "unique_site_ids = np.unique(site_ids)\n",
    "\n",
    "# Initialize indSite as a list to hold the indices\n",
    "inds_per_site = {}\n",
    "\n",
    "# Loop over each value in site ids\n",
    "for site_id in (unique_site_ids + 1):\n",
    "\n",
    "    # Find the indices where all elements in a row of siteDATA match the current valueSite\n",
    "    # Note: This assumes siteDATA and siteValues have compatible shapes or values for comparison\n",
    "    indices = np.where((site_ids == site_id-1).all(axis=1))[0]\n",
    "\n",
    "    # Append the found indices to the indSite list\n",
    "    inds_per_site[site_id] = indices\n",
    "\n",
    "# Delete the indices\n",
    "del indices\n",
    "\n",
    "# Initialise empty dict to store headers\n",
    "columns_for_sites = {}\n",
    "\n",
    "# Number of crossed terms we will consider\n",
    "n_ct = 0\n",
    "n_ct_per_site = {}\n",
    "\n",
    "# Create a dict of site-specific column headers\n",
    "for site_index in (unique_site_ids + 1):\n",
    "\n",
    "    # Get the columns for this site\n",
    "    columns_for_sites[site_index] = filter_columns_by_site(confounds, \n",
    "                                                           site_index, return_df=False)\n",
    "\n",
    "    # Add nonlinear columns\n",
    "    columns_for_sites[site_index] = columns_for_sites[site_index] + \\\n",
    "                                    filter_columns_by_site(nonlinear_confounds_reduced, \n",
    "                                                           site_index, return_df=False)\n",
    "\n",
    "    # Add the number of crossed terms for this site\n",
    "    n_ct_per_site[site_index] = int((len(columns_for_sites[site_index])-1)*(len(columns_for_sites[site_index]))/2)\n",
    "    n_ct = n_ct + n_ct_per_site[site_index]\n",
    "\n",
    "# Get number of subjects\n",
    "n_sub = len(sub_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff97dd1-e632-4bd4-a55e-0e10cd5a11cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now need to initialise a memory map of size n_sub by n_ct\n",
    "#ct = np.zeros((n_sub,n_ct))\n",
    "\n",
    "# for site_index in (unique_site_ids + 1):\n",
    "site_index = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce53d77-2e3a-438e-8e39-ff3e6705d4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Get the number of subjects for this site\n",
    "n_sub_site_i = len(inds_per_site[site_index])\n",
    "\n",
    "t1 = time.time()\n",
    "# Get the non-crossed confounds for site i\n",
    "conf_site_i = filter_columns_by_site(confounds[inds_per_site[site_index],:],site_index)\n",
    "conf_nonlin_site_i = filter_columns_by_site(nonlinear_confounds_reduced[inds_per_site[site_index],:],site_index)\n",
    "t2 = time.time()\n",
    "print(t2-t1)\n",
    "\n",
    "# Combine the two\n",
    "conf_site_i = pd.concat([conf_site_i,conf_nonlin_site_i], axis=1)\n",
    "\n",
    "# We now need to initialise a memory map of size n_sub by n_ct_per_site[site_index]\n",
    "ct_site_i = pd.DataFrame(np.zeros((n_sub_site_i, n_ct_per_site[site_index])))\n",
    "\n",
    "print(ct_site_i.shape, conf_site_i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6f8989-e8da-4912-8ba1-cc278b72f6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the site-specific columns\n",
    "site_cols = conf_site_i.columns\n",
    "\n",
    "# Current column we are adding crossed term for\n",
    "current_col = 0\n",
    "\n",
    "# List for column names\n",
    "col_names = []\n",
    "\n",
    "# Loop through generating confound terms\n",
    "for i in range(len(site_cols)):\n",
    "\n",
    "    # Cross term i with term j\n",
    "    for j in range(i):\n",
    "\n",
    "        # Add column name\n",
    "        col_names = col_names + [conf_site_i.columns[i] + '__x__' + conf_site_i.columns[j]]\n",
    "\n",
    "        # Add crossed term\n",
    "        ct_site_i.iloc[:,current_col] = conf_site_i.iloc[:,i]*conf_site_i.iloc[:,j]\n",
    "        \n",
    "        # Update current column\n",
    "        current_col = current_col + 1\n",
    "\n",
    "# Update columns in df\n",
    "ct_site_i.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2608e5f9-2c05-47d1-b50d-49112b0caab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "# Convert to memmapped dfs for memory management\n",
    "# ct_site_i = MemoryMappedDF(ct_site_i)\n",
    "# conf_site_i = MemoryMappedDF(conf_site_i)\n",
    "\n",
    "# Set cluster configuration\n",
    "local_cluster = {'cluster_type':'local','num_nodes':12}\n",
    "\n",
    "# Run nets_deconfound\n",
    "conf_ct_site_i = nets_deconfound(ct_site_i, conf_site_i,\n",
    "                                 'svd', \n",
    "                                 check_nan_patterns=True)\n",
    "\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf62fe-c833-4b49-b771-efaa6972dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_ct_site_i[conf_ct_site_i.abs()<1e-10]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a47a7a3-05de-4859-ab79-9b15d28d6ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_ct_site_i.index = inds_per_site[site_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f900b8dd-700a-4b15-b1d7-d6492888d752",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_ct_site_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db5f148-0612-4d24-a0a3-c9291f9ed21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe for crossed terms\n",
    "conf_ct = pd.DataFrame(index=confounds.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d2e685-78bb-4d5a-b343-a10afc252a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "conf_ct = pd.concat((conf_ct,conf_ct_site_i),axis=1).fillna(0)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ef5da3-62ec-46ff-bc57-f52530ded234",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_columns = np.sort(conf_ct.columns)\n",
    "\n",
    "conf_ct[[*sorted_columns]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09eb250-8d81-47f3-adf4-b4637fee9b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.script_01_09 import gen_ct_conf\n",
    "\n",
    "t1 = time.time()\n",
    "confounds_crossed_terms = gen_ct_conf(confounds, nonlinear_confounds_reduced, data_dir)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c3ace-e2e2-49aa-83ab-855c5b593be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "# Get full confounds\n",
    "conf_full = pd.concat((confounds[:,:],nonlinear_confounds_reduced[:,:]),axis=1)\n",
    "\n",
    "# Save as memory map\n",
    "conf_full = MemoryMappedDF(conf_full)\n",
    "t2 = time.time()\n",
    "print(t2-t1)\n",
    "\n",
    "print(conf_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5139f1c-21a9-43bb-9871-d7aa0d4cacc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_full[1:10,375:380]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0ce7cc-b994-4413-8d91-dc348a6fab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "# Set cluster configuration\n",
    "local_cluster = {'cluster_type':'local','num_nodes':12}\n",
    "\n",
    "# Deconfound using full confounds (but not crossed terms)\n",
    "IDPs_deconf_w_nonlin =  nets_deconfound(IDPs_deconf, conf_full,\n",
    "                                        'nets_svd', conf_has_nans=False,\n",
    "                                        check_nan_patterns=False,\n",
    "                                        cluster_cfg=local_cluster)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
